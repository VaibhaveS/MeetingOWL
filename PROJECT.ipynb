{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "dfaf798a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package nps_chat to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package nps_chat is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#! pip install PyAudio\n",
    "#! pip install SpeechRecognition\n",
    "import pandas as pd\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "#!pip install azure-cognitiveservices-speech\n",
    "#!pip install google-api-python-client \n",
    "#!pip install --upgrade google-cloud-speech\n",
    "#!pip install anvil-uplink\n",
    "#!pip install --upgrade google-api-python-client\n",
    "#!pip install --upgrade google-cloud-speech\n",
    "\n",
    "from azure.cognitiveservices.speech import AudioDataStream, SpeechConfig, SpeechSynthesizer, SpeechSynthesisOutputFormat\n",
    "from azure.cognitiveservices.speech.audio import AudioOutputConfig\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import anvil.server\n",
    "anvil.server.connect(\"XBQM36YNDUZ4TWI522HM4KDL-NUKYRRNENRSFFQ4A\")\n",
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"C:/Users/HP/Downloads/bionic-hallway-326706-923256f9f8eb.json\"\n",
    "import re\n",
    "import nltk.corpus\n",
    "from nltk.corpus import nps_chat\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('nps_chat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "a2ae1d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class isQuestion():\n",
    "    def __init__(self):\n",
    "        posts = nltk.corpus.nps_chat.xml_posts()\n",
    "        features = self.__get_feature_set(posts)\n",
    "        self.classifier = self.naiveBayes(features)\n",
    "    def __get_feature_set(self, posts):\n",
    "        feature = []\n",
    "        for post in posts:\n",
    "            post_text = post.text            \n",
    "            features = {}\n",
    "            words = nltk.word_tokenize(post_text)\n",
    "            for word in words:\n",
    "                features['contains({})'.format(word.lower())] = True\n",
    "            feature.append((features, post.get('class')))\n",
    "        return feature\n",
    "    def naiveBayes(self, feature_set):\n",
    "        training_size = int(len(feature_set) * 0.1)\n",
    "        train_set, test_set = feature_set[training_size:], feature_set[:training_size]\n",
    "        classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "        return classifier\n",
    "    def predict_question(self, text):\n",
    "        words = nltk.word_tokenize(text.lower())        \n",
    "        if '?' in text:\n",
    "            return 1\n",
    "        features = {}\n",
    "        for word in words:\n",
    "            features['contains({})'.format(word.lower())] = True            \n",
    "        prediction_result = self.classifier.classify(features)\n",
    "        print(prediction_result,text)\n",
    "        if prediction_result == 'whQuestion' or prediction_result == 'ynQuestion':\n",
    "            return 1\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "b62a9c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noOfSpeakers():\n",
    "    from google.cloud import speech_v1p1beta1 as speech\n",
    "    client = speech.SpeechClient()\n",
    "    speech_file = \"one.mp3\"\n",
    "    with open(speech_file, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "    gcs_uri = \"gs://nlp_j/MeetingOWL\"\n",
    "    audio = speech.RecognitionAudio(uri=gcs_uri)\n",
    "    diarization_config = speech.SpeakerDiarizationConfig(\n",
    "      enable_speaker_diarization=True,\n",
    "      min_speaker_count=2,\n",
    "      max_speaker_count=10,\n",
    "    )\n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding = speech.RecognitionConfig.AudioEncoding.ENCODING_UNSPECIFIED,\n",
    "        sample_rate_hertz=8000,\n",
    "        language_code=\"en-US\",\n",
    "        diarization_config=diarization_config,\n",
    "    )\n",
    "    operation = client.long_running_recognize(config=config, audio=audio)\n",
    "    response = operation.result(timeout=500)\n",
    "    for result in response.results:\n",
    "        words_info = result.alternatives[0].words\n",
    "    speakers = []\n",
    "    noOfSpeakers = 0\n",
    "    for word_info in words_info:\n",
    "        speakers.append(int(word_info.speaker_tag))\n",
    "    speakers = set(speakers)\n",
    "    return len(speakers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "ba44b090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def silience(file_name):\n",
    "    from pydub import AudioSegment,silence\n",
    "    myaudio = intro = AudioSegment.from_wav(file_name)\n",
    "    silence = silence.detect_silence(myaudio, min_silence_len=1000, silence_thresh=-16)\n",
    "    silence = [((start/1000),(stop/1000)) for start,stop in silence] #convert to sec\n",
    "    return silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "4570f7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#return the list of questions\n",
    "def Question_detection(transcript):\n",
    "    result = []\n",
    "    obj = isQuestion()\n",
    "    for i in transcript:\n",
    "        if(obj.predict_question(i) == 1):\n",
    "            result.append(i)\n",
    "    return result\n",
    "    #transcript is a list of setences ex. [\"hello everyone\",\"how is everyone\",\"lets start todays class\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "05707883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_blob(blob_name, bucket_name):\n",
    "    \"\"\"Deletes a blob from the bucket.\"\"\"\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    # blob_name = \"your-object-name\"\n",
    "\n",
    "    storage_client = storage.Client.from_service_account_json(\n",
    "        'C:/Users/HP/Downloads/bionic-hallway-326706-923256f9f8eb.json')\n",
    "\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    blob.delete()\n",
    "\n",
    "    print(\"Blob {} deleted.\".format(blob_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "1bd2b8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "def upload_to_bucket(blob_name, path_to_file, bucket_name):\n",
    "    \"\"\" Upload data to a bucket\"\"\"\n",
    "\n",
    "    # Explicitly use service account credentials by specifying the private key\n",
    "    # file.\n",
    "    storage_client = storage.Client.from_service_account_json(\n",
    "        'C:/Users/HP/Downloads/bionic-hallway-326706-923256f9f8eb.json')\n",
    "\n",
    "    #print(buckets = list(storage_client.list_buckets())\n",
    "\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    blob.upload_from_filename(path_to_file)\n",
    "\n",
    "    #returns a public url\n",
    "    return blob.public_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "b6811c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the Google Cloud client library\n",
    "def speech_to_text(file_path):\n",
    "    \n",
    "    from google.cloud import speech\n",
    "\n",
    "    gcs_uri=upload_to_bucket(\"MeetingOWL\",file_path,\"nlp_j\")\n",
    "    # Instantiates a client\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    # The name of the audio file to transcribe\n",
    "    gcs_uri = \"gs://nlp_j/MeetingOWL\"\n",
    "\n",
    "    audio = speech.RecognitionAudio(uri=gcs_uri)\n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        #encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        encoding= speech.RecognitionConfig.AudioEncoding.ENCODING_UNSPECIFIED,\n",
    "        sample_rate_hertz=16000,\n",
    "        language_code=\"en-IN\",enable_word_time_offsets=True,enable_automatic_punctuation=True,\n",
    "    )\n",
    "\n",
    "    # Detects speech in the audio file\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "    #print(response)\n",
    "    word_stamps=[]\n",
    "    transcript=[]\n",
    "    \n",
    "    for result in response.results:\n",
    "        alternative = result.alternatives[0]\n",
    "        for word_info in alternative.words:\n",
    "            word = word_info.word\n",
    "            start_time = word_info.start_time\n",
    "            end_time = word_info.end_time\n",
    "            word_stamps.append([word,start_time,end_time])\n",
    "        transcript.append(alternative.transcript)\n",
    "    delete_blob(\"MeetingOWL\",\"nlp_j\")\n",
    "    return [transcript,word_stamps]\n",
    "   # return response.results \n",
    "#speech_to_text(\"finally.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "9309ae68",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def my_tokenizer(doc):\n",
    "    words = word_tokenize(doc)\n",
    "    \n",
    "    pos_tags = pos_tag(words)\n",
    "    \n",
    "    non_stopwords = [w for w in pos_tags if not w[0].lower() in stopwords_list]\n",
    "    \n",
    "    non_punctuation = [w for w in non_stopwords if not w[0] in string.punctuation]\n",
    "    \n",
    "    lemmas = []\n",
    "    for w in non_punctuation:\n",
    "        if w[1].startswith('J'):\n",
    "            pos = wordnet.ADJ\n",
    "        elif w[1].startswith('V'):\n",
    "            pos = wordnet.VERB\n",
    "        elif w[1].startswith('N'):\n",
    "            pos = wordnet.NOUN\n",
    "        elif w[1].startswith('R'):\n",
    "            pos = wordnet.ADV\n",
    "        else:\n",
    "            pos = wordnet.NOUN\n",
    "        \n",
    "        lemmas.append(lemmatizer.lemmatize(w[0], pos))\n",
    "\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "4610dd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question,all_data,k,threshold,tfidf_vectorizer,tfidf_matrix):\n",
    "    query_vect = tfidf_vectorizer.transform([question])\n",
    "    similarity = cosine_similarity(query_vect, tfidf_matrix)[0]\n",
    "    sim=[]\n",
    "    for i in range(len(similarity)):\n",
    "        sim.append((similarity[i],i))\n",
    "    sim.sort(reverse=True)\n",
    "    #use the top k results \n",
    "    iteresting,difficult = 0,0\n",
    "\n",
    "    for max_indices in range(k):\n",
    "        print(all_data.iloc[sim[max_indices][1]]['Question'],all_data.iloc[sim[max_indices][1]]['Is the question difficult?'])\n",
    "        max_index=sim[max_indices][1]\n",
    "        max_sim = sim[max_indices][0]\n",
    "        weight_diff = -1\n",
    "        weight_interesting = -1\n",
    "        if(all_data.iloc[max_index]['Is the question difficult?']=='Yes'): weight_diff=1\n",
    "        if(all_data.iloc[max_index]['Is the question interesting?']=='Yes'): weight_interesting=1\n",
    "        difficult+= weight_diff*max_sim\n",
    "        iteresting+= weight_interesting*max_sim\n",
    "    \n",
    "    result={}\n",
    "    \n",
    "    if(difficult>=threshold):\n",
    "        result[\"difficulty\"]=\"Yes\"\n",
    "    else:\n",
    "        result[\"difficulty\"]=\"No\"\n",
    "    \n",
    "    if(iteresting>=threshold):\n",
    "        result[\"iteresting\"]=\"Yes\"\n",
    "    else:\n",
    "        result[\"iteresting\"]=\"No\"\n",
    "        \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "c502ba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interesting_questions(Questions,df,tfidf_vectorizer,tfidf_matrix):\n",
    "    diff,inter=0,0\n",
    "    for question in Questions:\n",
    "        response = ask_question(question,df,1,0,tfidf_vectorizer,tfidf_matrix)\n",
    "        print(\"khosan \",question,response)\n",
    "        if(response[\"difficulty\"]==\"Yes\"): diff+=1\n",
    "        if(response[\"iteresting\"]==\"Yes\"): inter+=1\n",
    "    return [diff,inter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "1b9019ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_data():\n",
    "    #path to the form responses\n",
    "    df = pd.read_csv(\"C:/Users/HP/Desktop/NLP_J/MeetingOWL/question_feedback.csv\")\n",
    "    df.iloc[0:,1:]\n",
    "    df=df.rename(columns={'Write a question relevant to our subjects which profs ask(eg. What is NLP?, Can someone tell me the difference between ML and AI? etc.)':'Question'})\n",
    "    tfidf_vectorizer = TfidfVectorizer(tokenizer=my_tokenizer)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(tuple(df['Question']))\n",
    "    return [df,tfidf_matrix,tfidf_vectorizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "21b7abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_transcript(transcript):\n",
    "    file1 = open('myfile.txt', 'w')\n",
    "    file1.writelines(transcript)\n",
    "    file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "2a37a6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anvil.media\n",
    "from shutil import copy\n",
    "@anvil.server.callable\n",
    "def write_media_to_file(media_object):\n",
    "    with anvil.media.TempFile(media_object) as f:\n",
    "        #audio file stored in finally.mp3\n",
    "        df,tfidf_matrix,tfidf_vectorizer=init_data()\n",
    "        copy(f, \"finally.mp3\")\n",
    "        #convert the speech to text\n",
    "        transcript,word_stamps=speech_to_text(\"finally.mp3\")\n",
    "        Questions = Question_detection(transcript)\n",
    "      #  Response_times = response_time(Questions,word_stamps,transcript)\n",
    "        diff,inter=interesting_questions(Questions,df,tfidf_vectorizer,tfidf_matrix)\n",
    "        speaker_count=noOfSpeakers()\n",
    "        test_transcript(transcript)\n",
    "        return [len(transcript),len(Questions),diff,inter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a367b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c69672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
