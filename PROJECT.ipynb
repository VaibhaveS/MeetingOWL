{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dfaf798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install PyAudio\n",
    "#! pip install SpeechRecognition\n",
    "import pandas as pd\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "#!pip install azure-cognitiveservices-speech\n",
    "#!pip install google-api-python-client \n",
    "#!pip install --upgrade google-cloud-speech\n",
    "#!pip install anvil-uplink\n",
    "#!pip install --upgrade google-api-python-client\n",
    "#!pip install --upgrade google-cloud-speech\n",
    "\n",
    "from azure.cognitiveservices.speech import AudioDataStream, SpeechConfig, SpeechSynthesizer, SpeechSynthesisOutputFormat\n",
    "from azure.cognitiveservices.speech.audio import AudioOutputConfig\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import anvil.server\n",
    "anvil.server.connect(\"XBQM36YNDUZ4TWI522HM4KDL-NUKYRRNENRSFFQ4A\")\n",
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"C:/Users/HP/Downloads/bionic-hallway-326706-923256f9f8eb.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a2ae1d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class isQuestionBasic():\n",
    "    def __init__(self):\n",
    "        self.nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "    def isQuestion(self, sentence):\n",
    "        if '?' in sentence:\n",
    "            return 1\n",
    "        output = self.nlp.annotate(sentence, properties={\n",
    "            'annotators': 'parse',\n",
    "            'outputFormat': 'json',\n",
    "            'timeout': 1000,\n",
    "        })\n",
    "        if ('SQ' or 'SBARQ') in output['sentences'][0][\"parse\"]:\n",
    "            return 1    \n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ba44b090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def silience(file_name):\n",
    "    from pydub import AudioSegment,silence\n",
    "    myaudio = intro = AudioSegment.from_wav(file_name)\n",
    "    silence = silence.detect_silence(myaudio, min_silence_len=1000, silence_thresh=-16)\n",
    "    silence = [((start/1000),(stop/1000)) for start,stop in silence] #convert to sec\n",
    "    return silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4570f7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Question_detection(transcript):\n",
    "    obj = isQuestionBasic()\n",
    "    #transcript is a list of setences ex. [\"hello everyone\",\"how is everyone\",\"lets start todays class\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "05707883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_blob(blob_name, bucket_name):\n",
    "    \"\"\"Deletes a blob from the bucket.\"\"\"\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    # blob_name = \"your-object-name\"\n",
    "\n",
    "    storage_client = storage.Client.from_service_account_json(\n",
    "        'C:/Users/HP/Downloads/bionic-hallway-326706-923256f9f8eb.json')\n",
    "\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    blob.delete()\n",
    "\n",
    "    print(\"Blob {} deleted.\".format(blob_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1bd2b8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "def upload_to_bucket(blob_name, path_to_file, bucket_name):\n",
    "    \"\"\" Upload data to a bucket\"\"\"\n",
    "\n",
    "    # Explicitly use service account credentials by specifying the private key\n",
    "    # file.\n",
    "    storage_client = storage.Client.from_service_account_json(\n",
    "        'C:/Users/HP/Downloads/bionic-hallway-326706-923256f9f8eb.json')\n",
    "\n",
    "    #print(buckets = list(storage_client.list_buckets())\n",
    "\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    blob.upload_from_filename(path_to_file)\n",
    "\n",
    "    #returns a public url\n",
    "    return blob.public_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b6811c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the Google Cloud client library\n",
    "def speech_to_text(file_path):\n",
    "    \n",
    "    from google.cloud import speech\n",
    "\n",
    "    upload_to_bucket(\"MeetingOWL\",file_path,\"nlp_j\")\n",
    "    # Instantiates a client\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    # The name of the audio file to transcribe\n",
    "    gcs_uri = \"gs://nlp_j/machine-learning_speech-recognition_30-4447-0004.wav\"\n",
    "\n",
    "    audio = speech.RecognitionAudio(uri=gcs_uri)\n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=16000,\n",
    "        language_code=\"en-US\",enable_word_time_offsets=True,enable_automatic_punctuation=True,\n",
    "    )\n",
    "\n",
    "    # Detects speech in the audio file\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "    #print(response)\n",
    "    word_stamps=[]\n",
    "    transcript=[]\n",
    "    \n",
    "    for result in response.results:\n",
    "        alternative = result.alternatives[0]\n",
    "        for word_info in alternative.words:\n",
    "            word = word_info.word\n",
    "            start_time = word_info.start_time\n",
    "            end_time = word_info.end_time\n",
    "            word_stamps.append([word,start_time,end_time])\n",
    "        transcript.append(alternative.transcript)\n",
    "    delete_blob(\"MeetingOWL\",\"nlp_j\")\n",
    "    return [transcript,word_stamps]\n",
    "   # return response.results \n",
    "#speech_to_text(\"finally.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c07ed8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9309ae68",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def my_tokenizer(doc):\n",
    "    words = word_tokenize(doc)\n",
    "    \n",
    "    pos_tags = pos_tag(words)\n",
    "    \n",
    "    non_stopwords = [w for w in pos_tags if not w[0].lower() in stopwords_list]\n",
    "    \n",
    "    non_punctuation = [w for w in non_stopwords if not w[0] in string.punctuation]\n",
    "    \n",
    "    lemmas = []\n",
    "    for w in non_punctuation:\n",
    "        if w[1].startswith('J'):\n",
    "            pos = wordnet.ADJ\n",
    "        elif w[1].startswith('V'):\n",
    "            pos = wordnet.VERB\n",
    "        elif w[1].startswith('N'):\n",
    "            pos = wordnet.NOUN\n",
    "        elif w[1].startswith('R'):\n",
    "            pos = wordnet.ADV\n",
    "        else:\n",
    "            pos = wordnet.NOUN\n",
    "        \n",
    "        lemmas.append(lemmatizer.lemmatize(w[0], pos))\n",
    "\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4610dd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question,all_data,k,threshold):\n",
    "    query_vect = tfidf_vectorizer.transform([question])\n",
    "    similarity = cosine_similarity(query_vect, tfidf_matrix)[0]\n",
    "    sim=[]\n",
    "    for i in range(len(similarity)):\n",
    "        sim.append((similarity[i],i))\n",
    "    sim.sort(reverse=True)\n",
    "    #use the top k results \n",
    "    iteresting,difficult = 0,0\n",
    "\n",
    "    for max_indices in range(k):\n",
    "        print(all_data.iloc[sim[max_indices][1]]['Question'],all_data.iloc[sim[max_indices][1]]['Is the question difficult?'])\n",
    "        max_index=sim[max_indices][1]\n",
    "        max_sim = sim[max_indices][0]\n",
    "        weight_diff = -1\n",
    "        weight_interesting = -1\n",
    "        if(all_data.iloc[max_index]['Is the question difficult?']=='Yes'): weight_diff=1\n",
    "        if(all_data.iloc[max_index]['Is the question interesting?']=='Yes'): weight_interesting=1\n",
    "        difficult+= weight_diff*max_sim\n",
    "        iteresting+= weight_interesting*max_sim\n",
    "    print('Your question:', question)\n",
    "    print('Is the Question difficult:',end=' ')\n",
    "    \n",
    "    if(difficult>=threshold):\n",
    "        print(\"Yes\")\n",
    "    else:\n",
    "        print(\"No\")\n",
    "    print('Is the Question interesting?:',end=' ')\n",
    "    if(iteresting>=threshold):\n",
    "        print(\"Yes\")\n",
    "    else:\n",
    "        print(\"No\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8297c9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anvil.media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6b7aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(cendel):\n",
    "    try:\n",
    "        anvil.media.download(cendel)\n",
    "    except AssertionError as error:\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc07e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anvil.media\n",
    "obj = isQuestionBasic()\n",
    "@anvil.server.callable\n",
    "def classify_question(question):\n",
    "    return write(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376fb28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anvil.media\n",
    "from shutil import copy\n",
    "@anvil.server.callable\n",
    "def write_media_to_file(media_object):\n",
    "    with anvil.media.TempFile(media_object) as f:\n",
    "        #audio file stored in finally.mp3\n",
    "        copy(f, \"finally.mp3\")\n",
    "        #convert the speech to text\n",
    "        transcript,word_stamps=speech_to_text(\"finally.mp3\")\n",
    "        #response_time()\n",
    "        #detect_questions()\n",
    "        #interesting_questions()\n",
    "        return \"Success\"\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f087108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to the form responses\n",
    "df = pd.read_csv(\"Desktop/NLP_J/question_feedback.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32522714",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0:,1:]\n",
    "df=df.rename(columns={'Write a question relevant to our subjects which profs ask(eg. What is NLP?, Can someone tell me the difference between ML and AI? etc.)':'Question'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7742ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=my_tokenizer)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(tuple(df['Question']))\n",
    "#print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ae493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ask_question('What is 2+2',df,3,0)\n",
    "# ask_question('What is the main purpose of OS',df,1,0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
